{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ChMChiJbyiY"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(json_path):\n",
        "    with open(json_path, 'r') as f:\n",
        "        return json.load(f)"
      ],
      "metadata": {
        "id": "ixbb7Ggzb08X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(user_data, win_size=10, step_size=5):\n",
        "    \"\"\"\n",
        "    Extracts fixed-length time-windowed features per user.\n",
        "    Combines accelerometer, gyroscope, and interaction event counts (tap/swipe/keypress).\n",
        "    \"\"\"\n",
        "    sessions = {}\n",
        "    for entry in user_data['unknown']:\n",
        "        user_id = entry['id']\n",
        "        sensor = entry['events']['sensor_events']\n",
        "        taps = entry['events']['tap_events']\n",
        "        swipes = entry['events']['swipe_events']\n",
        "        keys = entry['events']['keypress_events']\n",
        "\n",
        "        acc = [e for e in sensor if e['type'] == 'accelerometer']\n",
        "        gyro = [e for e in sensor if e['type'] == 'gyroscope']\n",
        "        features = []\n",
        "\n",
        "        for a, g in zip(acc, gyro):\n",
        "            try:\n",
        "                ts_a = datetime.fromisoformat(a['timestamp'])\n",
        "                ts_g = datetime.fromisoformat(g['timestamp'])\n",
        "                if abs((ts_a - ts_g).total_seconds()) > 0.1:\n",
        "                    continue\n",
        "                f = [a['x'], a['y'], a['z'], g['x'], g['y'], g['z']]\n",
        "                features.append((ts_a, f))\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        if not features:\n",
        "            continue\n",
        "\n",
        "        features.sort()\n",
        "        feats = [f for _, f in features]\n",
        "\n",
        "        taps_ts = [datetime.fromisoformat(e['timestamp']) for e in taps]\n",
        "        swipes_ts = [datetime.fromisoformat(e['timestamp']) for e in swipes]\n",
        "        keys_ts = [datetime.fromisoformat(e['timestamp']) for e in keys]\n",
        "\n",
        "        windows = []\n",
        "        for i in range(0, len(feats) - win_size, step_size):\n",
        "            window_feats = feats[i:i+win_size]\n",
        "            timestamps = [features[i + j][0] for j in range(win_size)]\n",
        "            start_ts, end_ts = timestamps[0], timestamps[-1]\n",
        "\n",
        "            tap_count = sum(start_ts <= t <= end_ts for t in taps_ts)\n",
        "            swipe_count = sum(start_ts <= t <= end_ts for t in swipes_ts)\n",
        "            key_count = sum(start_ts <= t <= end_ts for t in keys_ts)\n",
        "\n",
        "            flat_features = np.array(window_feats).flatten()\n",
        "            full_vector = np.concatenate([flat_features, [tap_count, swipe_count, key_count]])\n",
        "            windows.append(full_vector)\n",
        "\n",
        "        if windows:\n",
        "            if user_id not in sessions:\n",
        "                sessions[user_id] = []\n",
        "            sessions[user_id].extend(windows)\n",
        "\n",
        "    return sessions"
      ],
      "metadata": {
        "id": "hcSiZSKdb4A-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the dataset according to user-imposter format"
      ],
      "metadata": {
        "id": "Ql8xv_bVtY2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "for each user\n",
        " - groups all entries belonging to the same user into the pairs variable\n",
        " - groups all entries not belonging to the particular user into the neg_users variable\n",
        " - repeat for each user"
      ],
      "metadata": {
        "id": "yykB_8s_tdIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SiameseDataset(Dataset):\n",
        "    def __init__(self, features_by_user):\n",
        "        self.pairs = []\n",
        "        users = list(features_by_user.keys())\n",
        "        for uid in users:\n",
        "            samples = features_by_user[uid]\n",
        "            if len(samples) < 2:\n",
        "                continue\n",
        "            for i in range(len(samples) - 1):\n",
        "                # Positive pair (same user)\n",
        "                self.pairs.append((samples[i], samples[i+1], 1.0))\n",
        "                # Negative pair (different user)\n",
        "                neg_users = [u for u in users if u != uid]\n",
        "                if not neg_users:\n",
        "                    continue\n",
        "                neg_sample = features_by_user[neg_users[0]][0]\n",
        "                self.pairs.append((samples[i], neg_sample, 0.0))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x1, x2, label = self.pairs[idx]\n",
        "        return torch.tensor(x1, dtype=torch.float32), torch.tensor(x2, dtype=torch.float32), torch.tensor(label, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "RQ8Oou9tb75v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self, input_size, embedding_dim=128):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_size, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, embedding_dim)\n",
        "        )\n",
        "\n",
        "    def forward_once(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        emb1 = self.forward_once(x1)\n",
        "        emb2 = self.forward_once(x2)\n",
        "        return emb1, emb2\n"
      ],
      "metadata": {
        "id": "PeHzPOmXcBNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def contrastive_loss(emb1, emb2, label, margin=1.0):\n",
        "    distance = F.pairwise_distance(emb1, emb2)\n",
        "    loss = label * distance.pow(2) + (1 - label) * F.relu(margin - distance).pow(2)\n",
        "    return loss.mean()\n"
      ],
      "metadata": {
        "id": "yLZdd_4OcCz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, epochs=10, lr=1e-3):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for x1, x2, label in dataloader:\n",
        "            emb1, emb2 = model(x1, x2)\n",
        "            loss = contrastive_loss(emb1, emb2, label)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "d3CrLQ7KcEmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def verify(model, known_sample, test_sample, threshold=0.5):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        emb1, emb2 = model(\n",
        "            torch.tensor(known_sample, dtype=torch.float32).unsqueeze(0),\n",
        "            torch.tensor(test_sample, dtype=torch.float32).unsqueeze(0)\n",
        "        )\n",
        "        distance = F.pairwise_distance(emb1, emb2).item()\n",
        "        return distance < threshold, distance\n"
      ],
      "metadata": {
        "id": "LW6si2REcMvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_path = \"data_store1.json\"  # Change to your path if needed\n",
        "raw_data = load_data(json_path)\n",
        "feature_dict = extract_features(raw_data)\n",
        "\n",
        "sample_dim = len(next(iter(feature_dict.values()))[0])\n",
        "dataset = SiameseDataset(feature_dict)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "model = SiameseNetwork(input_size=sample_dim)\n",
        "train(model, dataloader, epochs=50)\n",
        "\n",
        "# Save model\n",
        "torch.save(model.state_dict(), \"bba_siamese_model.pt\")\n",
        "print(\"âœ… Model trained and saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFezkIdlcOGY",
        "outputId": "612dfcf6-a8d9-469c-9864-08a8fa2a899c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 73.4508\n",
            "Epoch 2/50, Loss: 17.7669\n",
            "Epoch 3/50, Loss: 9.5836\n",
            "Epoch 4/50, Loss: 6.4751\n",
            "Epoch 5/50, Loss: 4.5523\n",
            "Epoch 6/50, Loss: 3.5535\n",
            "Epoch 7/50, Loss: 2.7685\n",
            "Epoch 8/50, Loss: 2.2679\n",
            "Epoch 9/50, Loss: 2.0403\n",
            "Epoch 10/50, Loss: 1.6633\n",
            "Epoch 11/50, Loss: 1.3765\n",
            "Epoch 12/50, Loss: 1.2404\n",
            "Epoch 13/50, Loss: 1.0839\n",
            "Epoch 14/50, Loss: 0.9733\n",
            "Epoch 15/50, Loss: 0.8985\n",
            "Epoch 16/50, Loss: 0.7820\n",
            "Epoch 17/50, Loss: 0.7550\n",
            "Epoch 18/50, Loss: 0.7315\n",
            "Epoch 19/50, Loss: 0.6479\n",
            "Epoch 20/50, Loss: 0.5895\n",
            "Epoch 21/50, Loss: 0.5705\n",
            "Epoch 22/50, Loss: 0.5745\n",
            "Epoch 23/50, Loss: 0.5802\n",
            "Epoch 24/50, Loss: 0.5096\n",
            "Epoch 25/50, Loss: 0.4909\n",
            "Epoch 26/50, Loss: 0.4526\n",
            "Epoch 27/50, Loss: 0.4456\n",
            "Epoch 28/50, Loss: 0.5233\n",
            "Epoch 29/50, Loss: 0.4242\n",
            "Epoch 30/50, Loss: 0.6567\n",
            "Epoch 31/50, Loss: 0.5790\n",
            "Epoch 32/50, Loss: 0.4173\n",
            "Epoch 33/50, Loss: 0.3159\n",
            "Epoch 34/50, Loss: 0.3146\n",
            "Epoch 35/50, Loss: 0.3208\n",
            "Epoch 36/50, Loss: 0.2933\n",
            "Epoch 37/50, Loss: 0.2755\n",
            "Epoch 38/50, Loss: 0.2548\n",
            "Epoch 39/50, Loss: 0.2670\n",
            "Epoch 40/50, Loss: 0.2885\n",
            "Epoch 41/50, Loss: 0.2880\n",
            "Epoch 42/50, Loss: 0.2361\n",
            "Epoch 43/50, Loss: 0.2452\n",
            "Epoch 44/50, Loss: 0.2516\n",
            "Epoch 45/50, Loss: 0.2273\n",
            "Epoch 46/50, Loss: 0.2137\n",
            "Epoch 47/50, Loss: 0.1834\n",
            "Epoch 48/50, Loss: 0.1902\n",
            "Epoch 49/50, Loss: 0.1682\n",
            "Epoch 50/50, Loss: 0.1715\n",
            "âœ… Model trained and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "def load_model(model_path, input_size):\n",
        "    model = SiameseNetwork(input_size=input_size)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "def verify(model, known_sample, test_sample, threshold=0.5):\n",
        "    with torch.no_grad():\n",
        "        emb1, emb2 = model(\n",
        "            torch.tensor(known_sample, dtype=torch.float32).unsqueeze(0),\n",
        "            torch.tensor(test_sample, dtype=torch.float32).unsqueeze(0)\n",
        "        )\n",
        "        dist = F.pairwise_distance(emb1, emb2).item()\n",
        "        return dist < threshold, dist\n",
        "\n",
        "\n",
        "data = load_data(\"data_store1.json\")\n",
        "feature_dict = extract_features(data)\n",
        "\n",
        "user_ids = list(feature_dict.keys())\n",
        "assert len(user_ids) >= 2, \"Need at least 2 users for testing.\"\n",
        "\n",
        "user1_samples = feature_dict[user_ids[0]]\n",
        "user2_samples = feature_dict[user_ids[1]]\n",
        "\n",
        "known_sample = user1_samples[0]\n",
        "\n",
        "# Positive test: same user\n",
        "test_sample_same = user1_samples[1]\n",
        "# Negative test: different user\n",
        "test_sample_diff = user2_samples[0]\n",
        "\n",
        "input_size = len(known_sample)\n",
        "model = load_model(\"bba_siamese_model.pt\", input_size)\n",
        "\n",
        "# Run tests\n",
        "result_same, dist_same = verify(model, known_sample, test_sample_same)\n",
        "result_diff, dist_diff = verify(model, known_sample, test_sample_diff)\n",
        "\n",
        "print(\"\\nðŸ“Œ TEST RESULTS\")\n",
        "print(f\"[SAME USER]   Distance: {dist_same:.4f} | Match: {result_same}\")\n",
        "print(f\"[DIFF USER]   Distance: {dist_diff:.4f} | Match: {result_diff}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHhsBtrpcaRT",
        "outputId": "4d53fda2-8cad-4637-9cae-3ad9b8c2afc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Œ TEST RESULTS\n",
            "[SAME USER]   Distance: 1.0530 | Match: False\n",
            "[DIFF USER]   Distance: 1.7755 | Match: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the above output shows distance of 1 is not enough to classify imposter"
      ],
      "metadata": {
        "id": "z3Z2jviNt4LF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "def load_model(model_path, input_size):\n",
        "    model = SiameseNetwork(input_size=input_size)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "def verify(model, known_sample, test_sample, threshold=0.5):\n",
        "    with torch.no_grad():\n",
        "        emb1, emb2 = model(\n",
        "            torch.tensor(known_sample, dtype=torch.float32).unsqueeze(0),\n",
        "            torch.tensor(test_sample, dtype=torch.float32).unsqueeze(0)\n",
        "        )\n",
        "        dist = F.pairwise_distance(emb1, emb2).item()\n",
        "        return dist < threshold, dist\n",
        "\n",
        "\n",
        "    # Load data again (same file used during training)\n",
        "data = load_data(\"data_store1.json\")\n",
        "feature_dict = extract_features(data)\n",
        "\n",
        "user_ids = list(feature_dict.keys())\n",
        "assert len(user_ids) >= 2, \"Need at least 2 users for testing.\"\n",
        "\n",
        "user1_samples = feature_dict[user_ids[0]]\n",
        "user2_samples = feature_dict[user_ids[1]]\n",
        "\n",
        "# Use 1 sample from user 1 as known reference\n",
        "known_sample = user1_samples[0]\n",
        "\n",
        "# Positive test: same user\n",
        "test_sample_same = user1_samples[1]\n",
        "# Negative test: different user\n",
        "test_sample_diff = user2_samples[0]\n",
        "\n",
        "input_size = len(known_sample)\n",
        "model = load_model(\"bba_siamese_model.pt\", input_size)\n",
        "\n",
        "thresholds = np.arange(0.3, 2.0, 0.1)\n",
        "for t in thresholds:\n",
        "    same_match, d_same = verify(model, known_sample, test_sample_same, threshold=t)\n",
        "    diff_match, d_diff = verify(model, known_sample, test_sample_diff, threshold=t)\n",
        "    print(f\"Threshold {t:.1f} | SAME: {same_match} ({d_same:.3f}) | DIFF: {diff_match} ({d_diff:.3f})\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhmMEQjtdBaG",
        "outputId": "d60135b5-3b11-4ec1-d5a5-981e36816af0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold 0.3 | SAME: False (1.053) | DIFF: False (1.775)\n",
            "Threshold 0.4 | SAME: False (1.053) | DIFF: False (1.775)\n",
            "Threshold 0.5 | SAME: False (1.053) | DIFF: False (1.775)\n",
            "Threshold 0.6 | SAME: False (1.053) | DIFF: False (1.775)\n",
            "Threshold 0.7 | SAME: False (1.053) | DIFF: False (1.775)\n",
            "Threshold 0.8 | SAME: False (1.053) | DIFF: False (1.775)\n",
            "Threshold 0.9 | SAME: False (1.053) | DIFF: False (1.775)\n",
            "Threshold 1.0 | SAME: False (1.053) | DIFF: False (1.775)\n",
            "Threshold 1.1 | SAME: True (1.053) | DIFF: False (1.775)\n",
            "Threshold 1.2 | SAME: True (1.053) | DIFF: False (1.775)\n",
            "Threshold 1.3 | SAME: True (1.053) | DIFF: False (1.775)\n",
            "Threshold 1.4 | SAME: True (1.053) | DIFF: False (1.775)\n",
            "Threshold 1.5 | SAME: True (1.053) | DIFF: False (1.775)\n",
            "Threshold 1.6 | SAME: True (1.053) | DIFF: False (1.775)\n",
            "Threshold 1.7 | SAME: True (1.053) | DIFF: False (1.775)\n",
            "Threshold 1.8 | SAME: True (1.053) | DIFF: True (1.775)\n",
            "Threshold 1.9 | SAME: True (1.053) | DIFF: True (1.775)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "above we tested different threshold values to see which predicted diff user as imposter"
      ],
      "metadata": {
        "id": "F05Mzu_fuOZv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r0Rj2BRSuOIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "\n",
        "def load_model(model_path, input_size):\n",
        "    model = SiameseNetwork(input_size=input_size)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "def verify(model, known_sample, test_sample, threshold=1.2):\n",
        "    with torch.no_grad():\n",
        "        emb1, emb2 = model(\n",
        "            torch.tensor(known_sample, dtype=torch.float32).unsqueeze(0),\n",
        "            torch.tensor(test_sample, dtype=torch.float32).unsqueeze(0)\n",
        "        )\n",
        "        dist = F.pairwise_distance(emb1, emb2).item()\n",
        "        return dist < threshold, dist\n",
        "\n",
        "\n",
        "data = load_data(\"data_store1.json\")\n",
        "feature_dict = extract_features(data)\n",
        "\n",
        "user_ids = list(feature_dict.keys())\n",
        "print(f\"Found {len(user_ids)} users with data.\")\n",
        "\n",
        "# Filter out users with fewer than 2 samples\n",
        "user_ids = [u for u in user_ids if len(feature_dict[u]) >= 2]\n",
        "\n",
        "if len(user_ids) < 3:\n",
        "    print(\"Need at least 3 users with enough data to test.\")\n",
        "    exit()\n",
        "\n",
        "# Load trained model\n",
        "sample_size = len(feature_dict[user_ids[0]][0])\n",
        "model = load_model(\"bba_siamese_model.pt\", input_size=sample_size)\n",
        "\n",
        "threshold = 1.2\n",
        "print(f\"\\nðŸ“Š Running multi-user tests with threshold = {threshold}\\n\")\n",
        "\n",
        "# SAME-USER TESTS\n",
        "print(\"ðŸ” SAME-USER PAIRS\")\n",
        "for uid in user_ids[:3]:\n",
        "    samples = feature_dict[uid]\n",
        "    known_sample = samples[0]\n",
        "    test_sample = samples[1]\n",
        "    match, dist = verify(model, known_sample, test_sample, threshold)\n",
        "    print(f\"[User: {uid[:6]}] Distance: {dist:.4f} | Match: {match}\")\n",
        "\n",
        "# DIFFERENT-USER TESTS\n",
        "print(\"\\nâš”ï¸ DIFFERENT-USER PAIRS\")\n",
        "for u1, u2 in combinations(user_ids[:3], 2):\n",
        "    s1 = feature_dict[u1][0]\n",
        "    s2 = feature_dict[u2][0]\n",
        "    match, dist = verify(model, s1, s2, threshold)\n",
        "    print(f\"[Users: {u1[:6]} vs {u2[:6]}] Distance: {dist:.4f} | Match: {match}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE0igmN9dOSx",
        "outputId": "1db0405d-c196-49e6-ff3d-c4f61e7744dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3 users with data.\n",
            "Need at least 3 users with enough data to test.\n",
            "\n",
            "ðŸ“Š Running multi-user tests with threshold = 1.2\n",
            "\n",
            "ðŸ” SAME-USER PAIRS\n",
            "[User: bbc7f6] Distance: 1.0530 | Match: True\n",
            "[User: c9f16b] Distance: 0.5300 | Match: True\n",
            "\n",
            "âš”ï¸ DIFFERENT-USER PAIRS\n",
            "[Users: bbc7f6 vs c9f16b] Distance: 1.7755 | Match: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Above, a threshold of 1.2 was accurately able to seperate user data into real vs anomaly\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "T76BhbIQuWcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bvzG9irQucIw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}